{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb2b342",
   "metadata": {},
   "source": [
    "# Introduction: Feature Selection\n",
    "\n",
    "In this notebook we will apply feature engineering to the manual engineered features built in two previous kernels. We will reduce the number of features using several methods and then we will test the performance of the features using a fairly basic gradient boosting machine model. \n",
    "\n",
    "The main takeaways from this notebook are:\n",
    "\n",
    "* Going from 1465 total features to 536 and an AUC ROC of 0.783 on the public leaderboard\n",
    "* A further optional step to go to 342 features and an AUC ROC of 0.782\n",
    "\n",
    "The full set of features was built in [Part One](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering) and [Part Two](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering-p2) of Manual Feature Engineering\n",
    "\n",
    "We will use three methods for feature selection:\n",
    "\n",
    "1. Remove collinear features\n",
    "2. Remove features with greater than a threshold percentage of missing values\n",
    "3. Keep only the most relevant features using feature importances from a model\n",
    "\n",
    "We will also take a look at an example of applying PCA although we will not use this method for feature reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b966e",
   "metadata": {},
   "source": [
    "Standard imports for data science work. The LightGBM library is used for the gradient boosting machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a949be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# featuretools for automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# matplotlit and seaborn for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 22\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# modeling \n",
    "import lightgbm as lgb\n",
    "\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# memory management\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482efc1",
   "metadata": {},
   "source": [
    "* `train_bureau` is the training features built manually using the `bureau` and `bureau_balance` data\n",
    "* `train_previous` is the training features built manually using the `previous`, `cash`, `credit`, and `installments` data\n",
    "\n",
    "We first will see how many features we built over the manual engineering process. Here we use a couple of set operations to find the columns that are only in the `bureau`, only in the `previous`, and in both dataframes, indicating that there are `original` features from the `application` dataframe. Here we are working with a small subset of the data in order to not overwhelm the kernel. This code has also been run on the full dataset (we will take a look at some of the results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4985fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train_bureau = pd.read_csv('data/raw/train_bureau_raw.csv', nrows = 1000)\n",
    "test_bureau = pd.read_csv('data/raw/test_bureau_raw.csv', nrows = 1000)\n",
    "\n",
    "train_previous = pd.read_csv('data/raw/train_previous_raw.csv', nrows = 1000)\n",
    "test_previous = pd.read_csv('data/raw/test_previous_raw.csv', nrows = 1000)\n",
    "\n",
    "# All columns in dataframes\n",
    "bureau_columns = list(train_bureau.columns)\n",
    "previous_columns = list(train_previous.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dba955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 122 original features.\n",
      "There are 211 bureau and bureau balance features.\n",
      "There are 1003 previous Home Credit loan features.\n"
     ]
    }
   ],
   "source": [
    "# Bureau only features\n",
    "bureau_features = list(set(bureau_columns) - set(previous_columns))\n",
    "\n",
    "# Previous only features\n",
    "previous_features = list(set(previous_columns) - set(bureau_columns))\n",
    "\n",
    "# Original features will be in both datasets\n",
    "original_features = list(set(previous_columns) & set(bureau_columns))\n",
    "\n",
    "print('There are %d original features.' % len(original_features))\n",
    "print('There are %d bureau and bureau balance features.' % len(bureau_features))\n",
    "print('There are %d previous Home Credit loan features.' % len(previous_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a605c7",
   "metadata": {},
   "source": [
    "That gives us the number of features in each dataframe. Now we want to combine the data without creating any duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d443bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (1000, 1336)\n",
      "Testing shape:  (1000, 1335)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_bureau['TARGET']\n",
    "previous_features.append('SK_ID_CURR')\n",
    "\n",
    "train_ids = train_bureau['SK_ID_CURR']\n",
    "test_ids = test_bureau['SK_ID_CURR']\n",
    "\n",
    "# Merge the dataframes avoiding duplicating columns by subsetting train_previous\n",
    "train = train_bureau.merge(train_previous[previous_features], on = 'SK_ID_CURR')\n",
    "test = test_bureau.merge(test_previous[previous_features], on = 'SK_ID_CURR')\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040029c",
   "metadata": {},
   "source": [
    "Next we want to one-hot encode the dataframes. This doesn't give the full features since we are only working with a sample of the data and this will not create as many columns as one-hot encoding the entire dataset would. Doing this to the full dataset results in 1465 features.\n",
    "\n",
    "An important note in the code cell is where we __align the dataframes by the columns.__ This ensures we have the same columns in the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a32dc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (1000, 1438)\n",
      "Testing shape:  (1000, 1438)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# Match the columns in the dataframes\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedaf8a4",
   "metadata": {},
   "source": [
    "When we do this to the full dataset, we get __1465__ features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74152f",
   "metadata": {},
   "source": [
    "### Admit and Correct Mistakes!\n",
    "\n",
    "When doing manual feature engineering, I accidentally created some columns derived from the client id, `SK_ID_CURR`. As this is a unique identifier for each client, it should not have any predictive power, and we would not want to build a model trained on this \"feature\". Let's remove any columns built on the `SK_ID_CURR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f04a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 columns that contain SK_ID_CURR\n",
      "There are 0 columns that contain SK_ID_BUREAU\n",
      "There are 0 columns that contain SK_ID_PREV\n",
      "Training shape:  (1000, 1437)\n",
      "Testing shape:  (1000, 1437)\n"
     ]
    }
   ],
   "source": [
    "cols_with_id = [x for x in train.columns if 'SK_ID_CURR' in x]\n",
    "cols_with_bureau_id = [x for x in train.columns if 'SK_ID_BUREAU' in x]\n",
    "cols_with_previous_id = [x for x in train.columns if 'SK_ID_PREV' in x]\n",
    "print('There are %d columns that contain SK_ID_CURR' % len(cols_with_id))\n",
    "print('There are %d columns that contain SK_ID_BUREAU' % len(cols_with_bureau_id))\n",
    "print('There are %d columns that contain SK_ID_PREV' % len(cols_with_previous_id))\n",
    "\n",
    "train = train.drop(columns = cols_with_id)\n",
    "test = test.drop(columns = cols_with_id)\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007548d0",
   "metadata": {},
   "source": [
    "After applying this to the full dataset, we end up with __1416 __ features. More features might seem like a good thing, and they can be if they help our model learn. However, irrelevant features, highly correlated features, and missing values can prevent the model from learning and decrease generalization performance on the testing data. Therefore, we perform feature selection to keep only the most useful variables.\n",
    "\n",
    "We will start feature selection by focusing on collinear variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe682175",
   "metadata": {},
   "source": [
    "# Remove Collinear Variables\n",
    "\n",
    "Collinear variables are those which are highly correlated with one another. These can decrease the model's availablility to learn, decrease model interpretability, and decrease generalization performance on the test set. Clearly, these are three things we want to increase, so removing collinear variables is a useful step. We will establish an admittedly arbitrary threshold for removing collinear variables, and then remove one out of any pair of variables that is above that threshold. \n",
    "\n",
    "The code below identifies the highly correlated variables based on the absolute magnitude of the Pearson correlation coefficient being greater than 0.9. Again, this is not entirely accurate since we are dealing with such a limited section of the data. This code is for illustration purposes, but if we read in the entire dataset, it would work (if the kernels allowed it)! \n",
    "\n",
    "This code is adapted from [work by Chris Albon](https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fd26b",
   "metadata": {},
   "source": [
    "### Identify Correlated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e62d3ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.036836</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>0.035851</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>0.211766</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.064817</td>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.020465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>0.055960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429317</td>\n",
       "      <td>0.491143</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.088743</td>\n",
       "      <td>0.208663</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.045634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.064520</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.080291</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.043426</td>\n",
       "      <td>0.107476</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>0.036836</td>\n",
       "      <td>0.429317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.986046</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.098314</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.075595</td>\n",
       "      <td>0.009483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>0.055732</td>\n",
       "      <td>0.491143</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>0.106685</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>0.133969</td>\n",
       "      <td>0.036801</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>0.036308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>0.035851</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.986046</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.058535</td>\n",
       "      <td>0.115613</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>0.014077</td>\n",
       "      <td>0.094081</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.082543</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "CNT_CHILDREN          1.000000          0.055960    0.036836     0.055732   \n",
       "AMT_INCOME_TOTAL      0.055960          1.000000    0.429317     0.491143   \n",
       "AMT_CREDIT            0.036836          0.429317    1.000000     0.797209   \n",
       "AMT_ANNUITY           0.055732          0.491143    0.797209     1.000000   \n",
       "AMT_GOODS_PRICE       0.035851          0.439981    0.986046     0.799121   \n",
       "\n",
       "                  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "CNT_CHILDREN             0.035851                    0.060210    0.303782   \n",
       "AMT_INCOME_TOTAL         0.439981                    0.184339    0.088743   \n",
       "AMT_CREDIT               0.986046                    0.074287    0.065100   \n",
       "AMT_ANNUITY              0.799121                    0.106685    0.019480   \n",
       "AMT_GOODS_PRICE          1.000000                    0.073531    0.058535   \n",
       "\n",
       "                  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "CNT_CHILDREN           0.218535           0.211766         0.036960  ...   \n",
       "AMT_INCOME_TOTAL       0.208663           0.130682         0.045634  ...   \n",
       "AMT_CREDIT             0.116515           0.027876         0.022994  ...   \n",
       "AMT_ANNUITY            0.139220           0.059163         0.024020  ...   \n",
       "AMT_GOODS_PRICE        0.115613           0.034500         0.030878  ...   \n",
       "\n",
       "                  HOUSETYPE_MODE_terraced house  WALLSMATERIAL_MODE_Block  \\\n",
       "CNT_CHILDREN                           0.096914                  0.064817   \n",
       "AMT_INCOME_TOTAL                       0.033574                  0.064520   \n",
       "AMT_CREDIT                             0.005136                  0.011202   \n",
       "AMT_ANNUITY                            0.011107                  0.022890   \n",
       "AMT_GOODS_PRICE                        0.002397                  0.020737   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  \\\n",
       "CNT_CHILDREN                      0.024544                       0.019465   \n",
       "AMT_INCOME_TOTAL                  0.020186                       0.058210   \n",
       "AMT_CREDIT                        0.007313                       0.060005   \n",
       "AMT_ANNUITY                       0.017907                       0.084270   \n",
       "AMT_GOODS_PRICE                   0.000716                       0.069845   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Others  WALLSMATERIAL_MODE_Panel  \\\n",
       "CNT_CHILDREN                       0.005586                  0.030986   \n",
       "AMT_INCOME_TOTAL                   0.060465                  0.080291   \n",
       "AMT_CREDIT                         0.009795                  0.098314   \n",
       "AMT_ANNUITY                        0.022107                  0.133969   \n",
       "AMT_GOODS_PRICE                    0.014077                  0.094081   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "CNT_CHILDREN                             0.001443                   0.027967   \n",
       "AMT_INCOME_TOTAL                         0.000218                   0.043426   \n",
       "AMT_CREDIT                               0.018123                   0.009507   \n",
       "AMT_ANNUITY                              0.036801                   0.032497   \n",
       "AMT_GOODS_PRICE                          0.012866                   0.019114   \n",
       "\n",
       "                  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \n",
       "CNT_CHILDREN                    0.004500                 0.020465  \n",
       "AMT_INCOME_TOTAL                0.107476                 0.030645  \n",
       "AMT_CREDIT                      0.075595                 0.009483  \n",
       "AMT_ANNUITY                     0.098291                 0.036308  \n",
       "AMT_GOODS_PRICE                 0.082543                 0.000395  \n",
       "\n",
       "[5 rows x 1437 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = train.corr().abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238682c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05596</td>\n",
       "      <td>0.036836</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>0.035851</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>0.211766</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.064817</td>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.020465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429317</td>\n",
       "      <td>0.491143</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.088743</td>\n",
       "      <td>0.208663</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.045634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.064520</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.080291</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.043426</td>\n",
       "      <td>0.107476</td>\n",
       "      <td>0.030645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.986046</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.098314</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.075595</td>\n",
       "      <td>0.009483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>0.106685</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>0.133969</td>\n",
       "      <td>0.036801</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>0.036308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.058535</td>\n",
       "      <td>0.115613</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>0.014077</td>\n",
       "      <td>0.094081</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.082543</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "CNT_CHILDREN               NaN           0.05596    0.036836     0.055732   \n",
       "AMT_INCOME_TOTAL           NaN               NaN    0.429317     0.491143   \n",
       "AMT_CREDIT                 NaN               NaN         NaN     0.797209   \n",
       "AMT_ANNUITY                NaN               NaN         NaN          NaN   \n",
       "AMT_GOODS_PRICE            NaN               NaN         NaN          NaN   \n",
       "\n",
       "                  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "CNT_CHILDREN             0.035851                    0.060210    0.303782   \n",
       "AMT_INCOME_TOTAL         0.439981                    0.184339    0.088743   \n",
       "AMT_CREDIT               0.986046                    0.074287    0.065100   \n",
       "AMT_ANNUITY              0.799121                    0.106685    0.019480   \n",
       "AMT_GOODS_PRICE               NaN                    0.073531    0.058535   \n",
       "\n",
       "                  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "CNT_CHILDREN           0.218535           0.211766         0.036960  ...   \n",
       "AMT_INCOME_TOTAL       0.208663           0.130682         0.045634  ...   \n",
       "AMT_CREDIT             0.116515           0.027876         0.022994  ...   \n",
       "AMT_ANNUITY            0.139220           0.059163         0.024020  ...   \n",
       "AMT_GOODS_PRICE        0.115613           0.034500         0.030878  ...   \n",
       "\n",
       "                  HOUSETYPE_MODE_terraced house  WALLSMATERIAL_MODE_Block  \\\n",
       "CNT_CHILDREN                           0.096914                  0.064817   \n",
       "AMT_INCOME_TOTAL                       0.033574                  0.064520   \n",
       "AMT_CREDIT                             0.005136                  0.011202   \n",
       "AMT_ANNUITY                            0.011107                  0.022890   \n",
       "AMT_GOODS_PRICE                        0.002397                  0.020737   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  \\\n",
       "CNT_CHILDREN                      0.024544                       0.019465   \n",
       "AMT_INCOME_TOTAL                  0.020186                       0.058210   \n",
       "AMT_CREDIT                        0.007313                       0.060005   \n",
       "AMT_ANNUITY                       0.017907                       0.084270   \n",
       "AMT_GOODS_PRICE                   0.000716                       0.069845   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Others  WALLSMATERIAL_MODE_Panel  \\\n",
       "CNT_CHILDREN                       0.005586                  0.030986   \n",
       "AMT_INCOME_TOTAL                   0.060465                  0.080291   \n",
       "AMT_CREDIT                         0.009795                  0.098314   \n",
       "AMT_ANNUITY                        0.022107                  0.133969   \n",
       "AMT_GOODS_PRICE                    0.014077                  0.094081   \n",
       "\n",
       "                  WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "CNT_CHILDREN                             0.001443                   0.027967   \n",
       "AMT_INCOME_TOTAL                         0.000218                   0.043426   \n",
       "AMT_CREDIT                               0.018123                   0.009507   \n",
       "AMT_ANNUITY                              0.036801                   0.032497   \n",
       "AMT_GOODS_PRICE                          0.012866                   0.019114   \n",
       "\n",
       "                  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \n",
       "CNT_CHILDREN                    0.004500                 0.020465  \n",
       "AMT_INCOME_TOTAL                0.107476                 0.030645  \n",
       "AMT_CREDIT                      0.075595                 0.009483  \n",
       "AMT_ANNUITY                     0.098291                 0.036308  \n",
       "AMT_GOODS_PRICE                 0.082543                 0.000395  \n",
       "\n",
       "[5 rows x 1437 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a58de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 638 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd9297",
   "metadata": {},
   "source": [
    "#### Drop Correlated Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9d98c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (1000, 799)\n",
      "Testing shape:  (1000, 799)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(columns = to_drop)\n",
    "test = test.drop(columns = to_drop)\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b9903",
   "metadata": {},
   "source": [
    "Applying this on the entire dataset __results in 538  collinear features__ removed.  \n",
    "\n",
    "This has reduced the number of features singificantly, but it is likely still too many. At this point, we'll read in the full dataset after removing correlated variables for further feature selection.\n",
    "\n",
    "The full datasets (after removing correlated variables) are available in `m_train_combined.csv` and `m_test_combined.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c582a5",
   "metadata": {},
   "source": [
    "### Read in Full Dataset\n",
    "\n",
    "Now we are ready to move on to the full set of features. These were built by applying the above steps to the entire `train_bureau` and `train_previous` files (you can do the same if you want and have the computational resources)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dd3cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/raw/m_train_combined.csv')\n",
    "test = pd.read_csv('data/raw/m_test_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ae8ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set full shape:  (307511, 865)\n",
      "Testing set full shape:  (48744, 864)\n"
     ]
    }
   ],
   "source": [
    "print('Training set full shape: ', train.shape)\n",
    "print('Testing set full shape: ' , test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a4884b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0             0          202500.0    406597.5      24700.5   \n",
       "1             0          270000.0   1293502.5      35698.5   \n",
       "2             0           67500.0    135000.0       6750.0   \n",
       "3             0          135000.0    312682.5      29686.5   \n",
       "4             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.018801       -9461           -637            -3648.0   \n",
       "1                    0.003541      -16765          -1188            -1186.0   \n",
       "2                    0.010032      -19046           -225            -4260.0   \n",
       "3                    0.008019      -19005          -3039            -9833.0   \n",
       "4                    0.028663      -19932          -3038            -4311.0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  OWN_CAR_AGE  ...  WALLSMATERIAL_MODE_Block  \\\n",
       "0            -2120          NaN  ...                         0   \n",
       "1             -291          NaN  ...                         1   \n",
       "2            -2531         26.0  ...                         0   \n",
       "3            -2437          NaN  ...                         0   \n",
       "4            -3458          NaN  ...                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "3                         0                              0   \n",
       "4                         0                              0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Others  WALLSMATERIAL_MODE_Panel  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "0                                1                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "\n",
       "   EMERGENCYSTATE_MODE_Yes  SK_ID_CURR  TARGET  \n",
       "0                        0      100002       1  \n",
       "1                        0      100003       0  \n",
       "2                        0      100004       0  \n",
       "3                        0      100006       0  \n",
       "4                        0      100007       0  \n",
       "\n",
       "[5 rows x 865 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31cb4d",
   "metadata": {},
   "source": [
    "# Remove Missing Values\n",
    "\n",
    "A relatively simple choice of feature selection is removing missing values. Well, it seems simple, at least until we have to decide what percentage of missing values is the minimum threshold for removing a column. Like many choices in machine learning, there is no right answer, and not even a general rule of thumb for making this choice. In this implementation, if any columns have greater than 75% missing values, they will be removed. \n",
    "\n",
    "Most models (including those in Sk-Learn) cannot handle missing values, so we will have to fill these in before machine learning. The Gradient Boosting Machine ([at least in LightGBM](https://github.com/Microsoft/LightGBM/blob/master/docs/Advanced-Topics.rst)) can handle missing values. Imputing missing values always makes me a little uncomfortable because we are adding information that actually isn't in the dataset. Since we are going to be evaluating several models (in a later notebook), we will have to use some form of imputation. For now, we will focus on removing columns above the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8686d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_credit_AMT_PAYMENT_CURRENT_min_min            0.801438\n",
       "client_credit_AMT_PAYMENT_CURRENT_mean_max           0.801438\n",
       "client_credit_AMT_DRAWINGS_OTHER_CURRENT_min_mean    0.801178\n",
       "client_credit_AMT_DRAWINGS_OTHER_CURRENT_mean_min    0.801178\n",
       "client_credit_AMT_DRAWINGS_POS_CURRENT_mean_mean     0.801178\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train missing values (in percent)\n",
    "train_missing = (train.isnull().sum() / len(train)).sort_values(ascending = False)\n",
    "train_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d5a2a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_max    0.773223\n",
       "client_credit_AMT_DRAWINGS_OTHER_CURRENT_max_max     0.773223\n",
       "client_credit_CNT_DRAWINGS_ATM_CURRENT_mean_mean     0.773223\n",
       "client_credit_AMT_DRAWINGS_POS_CURRENT_mean_mean     0.773223\n",
       "client_credit_AMT_DRAWINGS_POS_CURRENT_min_min       0.773223\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test missing values (in percent)\n",
    "test_missing = (test.isnull().sum() / len(test)).sort_values(ascending = False)\n",
    "test_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2f85ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_credit_AMT_PAYMENT_CURRENT_min_min',\n",
       "       'client_credit_AMT_PAYMENT_CURRENT_mean_max',\n",
       "       'client_credit_AMT_DRAWINGS_OTHER_CURRENT_min_mean',\n",
       "       'client_credit_AMT_DRAWINGS_OTHER_CURRENT_mean_min',\n",
       "       'client_credit_AMT_DRAWINGS_POS_CURRENT_mean_mean',\n",
       "       'client_credit_AMT_DRAWINGS_ATM_CURRENT_min_mean',\n",
       "       'client_credit_AMT_DRAWINGS_ATM_CURRENT_mean_max',\n",
       "       'client_credit_AMT_DRAWINGS_ATM_CURRENT_max_mean',\n",
       "       'client_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_max',\n",
       "       'client_credit_CNT_DRAWINGS_ATM_CURRENT_max_min',\n",
       "       'client_credit_CNT_DRAWINGS_OTHER_CURRENT_max_max',\n",
       "       'client_credit_AMT_DRAWINGS_OTHER_CURRENT_max_max',\n",
       "       'client_credit_CNT_DRAWINGS_POS_CURRENT_min_mean',\n",
       "       'client_credit_CNT_DRAWINGS_ATM_CURRENT_min_max',\n",
       "       'client_credit_CNT_DRAWINGS_OTHER_CURRENT_min_max',\n",
       "       'client_credit_AMT_DRAWINGS_POS_CURRENT_max_max',\n",
       "       'client_credit_AMT_DRAWINGS_POS_CURRENT_min_min',\n",
       "       'client_credit_CNT_DRAWINGS_POS_CURRENT_mean_max',\n",
       "       'client_credit_CNT_DRAWINGS_ATM_CURRENT_mean_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de3b57fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Identify missing values above threshold\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_missing \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_missing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m[train_missing \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.75\u001b[39m]\n\u001b[0;32m      3\u001b[0m test_missing \u001b[38;5;241m=\u001b[39m test_missing\u001b[38;5;241m.\u001b[39mindex[test_missing \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.75\u001b[39m]\n\u001b[0;32m      5\u001b[0m all_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mset\u001b[39m(train_missing) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(test_missing)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# Identify missing values above threshold\n",
    "train_missing = train_missing.index[train_missing > 0.75]\n",
    "test_missing = test_missing.index[test_missing > 0.75]\n",
    "\n",
    "all_missing = list(set(set(train_missing) | set(test_missing)))\n",
    "print('There are %d columns with more than 75%% missing values' % len(all_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae508a50",
   "metadata": {},
   "source": [
    "Let's drop the columns, one-hot encode the dataframes, and then align the columns of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3d8a713",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m train_ids \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSK_ID_CURR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m test_ids \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSK_ID_CURR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(train\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[43mall_missing\u001b[49m))\n\u001b[0;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(test\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m all_missing))\n\u001b[0;32m      9\u001b[0m train, test \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39malign(test, join \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_missing' is not defined"
     ]
    }
   ],
   "source": [
    "# Need to save the labels because aligning will remove this column\n",
    "train_labels = train[\"TARGET\"]\n",
    "train_ids = train['SK_ID_CURR']\n",
    "test_ids = test['SK_ID_CURR']\n",
    "\n",
    "train = pd.get_dummies(train.drop(columns = all_missing))\n",
    "test = pd.get_dummies(test.drop(columns = all_missing))\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "print('Training set full shape: ', train.shape)\n",
    "print('Testing set full shape: ' , test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2159b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
